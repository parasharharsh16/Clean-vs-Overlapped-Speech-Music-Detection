{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_loader\n"
     ]
    }
   ],
   "source": [
    "from dataloader import dataloader, SignalDataset\n",
    "from utils import prepare_data\n",
    "from param import dataset_path, sample_universe_size\n",
    "from torch.utils.data import ConcatDataset\n",
    "from MTL_w_cascade_info import MtlCascadeModel\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch\n",
    "\n",
    "# from torch.nn.utils import weight_norm\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "hp = {\n",
    "    \"n_layers\": 1,\n",
    "    \"sp_hidden_nodes\": 20,\n",
    "    \"n_sp_hidden_lyrs\": 1,\n",
    "    \"mu_hidden_nodes\": 20,\n",
    "    \"n_mu_hidden_lyrs\": 1,\n",
    "    \"smr_hidden_nodes\": 20,\n",
    "    \"n_smr_hidden_lyrs\": 1,\n",
    "    \"n_epochs\": 100,\n",
    "    \"batch_size\": 20,\n",
    "    \"train_ratio\": 0.8,\n",
    "}\n",
    "combined_dataset = torch.load('dataset.pth')\n",
    "print(\"data_loader\")\n",
    "train_loader, test_loader = dataloader(\n",
    "    datasets=combined_dataset,\n",
    "    train_ratio=hp[\"train_ratio\"],\n",
    "    train_batch_size=hp[\"batch_size\"],\n",
    "    test_batch_size=1,\n",
    ")\n",
    "\n",
    "def train(\n",
    "    train_loader,\n",
    "    model,\n",
    "    epoch,\n",
    "    out_dict,\n",
    "    loss_sp_fn,\n",
    "    loss_mu_fn,\n",
    "    loss_smr_fn,\n",
    "    optimizer,\n",
    "):\n",
    "    correct = 0\n",
    "    for data in train_loader:\n",
    "        feature, label = data\n",
    "        y = [out_dict[x] for x in label]\n",
    "        out_sp, out_mu, out_smr = model(feature)\n",
    "\n",
    "        sp_list = [inner_list[0] for inner_list in y]\n",
    "        mu_list = [inner_list[1] for inner_list in y]\n",
    "        smr_list = [inner_list[2:] for inner_list in y]\n",
    "        y_sp = torch.Tensor(sp_list).unsqueeze(1)\n",
    "        y_mu = torch.Tensor(mu_list).unsqueeze(1)\n",
    "        y_smr = torch.Tensor(smr_list).unsqueeze(1)\n",
    "\n",
    "        loss_sp = loss_sp_fn(out_sp, y_sp)\n",
    "        loss_mu = loss_mu_fn(out_mu, y_mu)\n",
    "        loss_smr = loss_smr_fn(out_smr, y_smr)\n",
    "\n",
    "        total_loss = loss_sp + loss_mu + loss_smr\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred_y = torch.cat((out_sp, out_mu, out_smr), dim=1)\n",
    "        result = (pred_y > 0.5).float()\n",
    "        target = torch.tensor(y).float()\n",
    "        for i in range(result.size(0)):\n",
    "            if torch.all(torch.eq(result[i], target[i])):\n",
    "                correct += 1\n",
    "    accuracy = correct / len(train_loader.dataset)\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, Loss_sp: {loss_sp}, Loss_mu: {loss_mu}, Loss_smr: {loss_smr}, Accuracy: {accuracy}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_init\n",
      "start_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateeks/projects/iitj/su/Speech-Understanding-Minor/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([20, 1, 2])) that is different to the input size (torch.Size([20, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prateeks/projects/iitj/su/Speech-Understanding-Minor/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8, 1, 2])) that is different to the input size (torch.Size([8, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss_sp: 0.5497570037841797, Loss_mu: 1.669691562652588, Loss_smr: 0.08134792745113373, Accuracy: 0.22821576763485477\n",
      "Epoch: 2, Loss_sp: 0.12731775641441345, Loss_mu: 0.3549463748931885, Loss_smr: 0.1975173056125641, Accuracy: 0.36751630112625966\n",
      "Epoch: 3, Loss_sp: 0.13728009164333344, Loss_mu: 0.4615171551704407, Loss_smr: 0.19479364156723022, Accuracy: 0.4013040901007706\n",
      "Epoch: 4, Loss_sp: 0.18401402235031128, Loss_mu: 0.39979904890060425, Loss_smr: 0.3128724694252014, Accuracy: 0.41567871962062836\n",
      "Epoch: 5, Loss_sp: 0.07096236944198608, Loss_mu: 0.4647606313228607, Loss_smr: 0.23608353734016418, Accuracy: 0.40915826911677533\n",
      "Epoch: 6, Loss_sp: 0.35188257694244385, Loss_mu: 0.545046865940094, Loss_smr: 0.19359494745731354, Accuracy: 0.43375815056312983\n",
      "Epoch: 7, Loss_sp: 0.19236329197883606, Loss_mu: 0.5008758902549744, Loss_smr: 0.2694648802280426, Accuracy: 0.4350918790752816\n",
      "Epoch: 8, Loss_sp: 1.4852579832077026, Loss_mu: 0.21463799476623535, Loss_smr: 0.15860165655612946, Accuracy: 0.4460580912863071\n",
      "Epoch: 9, Loss_sp: 0.7786109447479248, Loss_mu: 1.4333815574645996, Loss_smr: 0.2365739941596985, Accuracy: 0.44101956135151155\n",
      "Epoch: 10, Loss_sp: 0.45253580808639526, Loss_mu: 0.7057640552520752, Loss_smr: 0.23522034287452698, Accuracy: 0.45583876704208653\n",
      "Epoch: 11, Loss_sp: 0.39727020263671875, Loss_mu: 0.44263607263565063, Loss_smr: 0.23619888722896576, Accuracy: 0.45643153526970953\n",
      "Epoch: 12, Loss_sp: 0.6125422716140747, Loss_mu: 1.2083640098571777, Loss_smr: 0.28254109621047974, Accuracy: 0.46680497925311204\n",
      "Epoch: 13, Loss_sp: 0.08395571261644363, Loss_mu: 1.084690809249878, Loss_smr: 0.14721539616584778, Accuracy: 0.46828689982216953\n",
      "Epoch: 14, Loss_sp: 0.09495381265878677, Loss_mu: 0.25495126843452454, Loss_smr: 0.15970373153686523, Accuracy: 0.4718435091879075\n",
      "Epoch: 15, Loss_sp: 0.0698404386639595, Loss_mu: 0.18575160205364227, Loss_smr: 0.11056943237781525, Accuracy: 0.4788085358624778\n",
      "Epoch: 16, Loss_sp: 0.04318779334425926, Loss_mu: 0.7130489349365234, Loss_smr: 0.15028204023838043, Accuracy: 0.47347362181387076\n",
      "Epoch: 17, Loss_sp: 0.0818684846162796, Loss_mu: 0.27545076608657837, Loss_smr: 0.19290493428707123, Accuracy: 0.48651452282157676\n",
      "Epoch: 18, Loss_sp: 0.1725568026304245, Loss_mu: 0.4179637134075165, Loss_smr: 0.23797300457954407, Accuracy: 0.46799051570835803\n",
      "Epoch: 19, Loss_sp: 0.1919795572757721, Loss_mu: 0.3622596263885498, Loss_smr: 0.1918148696422577, Accuracy: 0.472732661529342\n",
      "Epoch: 20, Loss_sp: 0.07556981593370438, Loss_mu: 0.18951784074306488, Loss_smr: 0.1937735229730606, Accuracy: 0.4791049199762893\n",
      "Epoch: 21, Loss_sp: 0.056652434170246124, Loss_mu: 0.3204583525657654, Loss_smr: 0.23690558969974518, Accuracy: 0.4842916419679905\n",
      "Epoch: 22, Loss_sp: 0.06018221378326416, Loss_mu: 0.09107986092567444, Loss_smr: 0.23660966753959656, Accuracy: 0.4854771784232365\n",
      "Epoch: 23, Loss_sp: 0.06560888886451721, Loss_mu: 0.3257613480091095, Loss_smr: 0.32533442974090576, Accuracy: 0.4842916419679905\n",
      "Epoch: 24, Loss_sp: 0.10355797410011292, Loss_mu: 0.15672357380390167, Loss_smr: 0.23507201671600342, Accuracy: 0.485773562537048\n",
      "Epoch: 25, Loss_sp: 0.49295443296432495, Loss_mu: 0.532962441444397, Loss_smr: 0.23693539202213287, Accuracy: 0.48295791345583877\n",
      "Epoch: 26, Loss_sp: 0.002992207184433937, Loss_mu: 0.35979998111724854, Loss_smr: 0.15272091329097748, Accuracy: 0.4890337877889745\n",
      "Epoch: 27, Loss_sp: 0.9586302638053894, Loss_mu: 0.2806282341480255, Loss_smr: 0.19513411819934845, Accuracy: 0.4884410195613515\n",
      "Epoch: 28, Loss_sp: 0.030592553317546844, Loss_mu: 0.49703091382980347, Loss_smr: 0.23568610846996307, Accuracy: 0.4949614700652045\n",
      "Epoch: 29, Loss_sp: 0.3449230492115021, Loss_mu: 0.3887611925601959, Loss_smr: 0.19349335134029388, Accuracy: 0.4927385892116183\n",
      "Epoch: 30, Loss_sp: 0.044806528836488724, Loss_mu: 0.502322256565094, Loss_smr: 0.23655974864959717, Accuracy: 0.49155305275637223\n",
      "Epoch: 31, Loss_sp: 0.0604616180062294, Loss_mu: 0.2117225080728531, Loss_smr: 0.15220046043395996, Accuracy: 0.5001481920569057\n",
      "Epoch: 32, Loss_sp: 0.027247650548815727, Loss_mu: 0.8172510862350464, Loss_smr: 0.27797266840934753, Accuracy: 0.49688796680497926\n",
      "Epoch: 33, Loss_sp: 0.023280655965209007, Loss_mu: 0.4211570918560028, Loss_smr: 0.193600133061409, Accuracy: 0.5056312981624185\n",
      "Epoch: 34, Loss_sp: 0.0258139930665493, Loss_mu: 0.9352917671203613, Loss_smr: 0.1279202401638031, Accuracy: 0.4979253112033195\n",
      "Epoch: 35, Loss_sp: 0.26903030276298523, Loss_mu: 0.2337425947189331, Loss_smr: 0.27614015340805054, Accuracy: 0.495257854179016\n",
      "Epoch: 36, Loss_sp: 0.1445968896150589, Loss_mu: 0.44997668266296387, Loss_smr: 0.19494003057479858, Accuracy: 0.499407231772377\n",
      "Epoch: 37, Loss_sp: 1.4519846439361572, Loss_mu: 0.6738405227661133, Loss_smr: 0.19234758615493774, Accuracy: 0.5105216360403082\n",
      "Epoch: 38, Loss_sp: 0.10961218178272247, Loss_mu: 0.23489254713058472, Loss_smr: 0.19271647930145264, Accuracy: 0.5026674570243035\n",
      "Epoch: 39, Loss_sp: 0.3239405155181885, Loss_mu: 0.22391264140605927, Loss_smr: 0.19444876909255981, Accuracy: 0.5072614107883817\n",
      "Epoch: 40, Loss_sp: 0.02873827889561653, Loss_mu: 0.21354258060455322, Loss_smr: 0.19468092918395996, Accuracy: 0.5026674570243035\n",
      "Epoch: 41, Loss_sp: 0.6267442107200623, Loss_mu: 0.3553236424922943, Loss_smr: 0.3155795633792877, Accuracy: 0.502371072910492\n",
      "Epoch: 42, Loss_sp: 0.012759498320519924, Loss_mu: 0.4984821081161499, Loss_smr: 0.32118529081344604, Accuracy: 0.5038529934795495\n",
      "Epoch: 43, Loss_sp: 1.040339469909668, Loss_mu: 0.19904229044914246, Loss_smr: 0.19458116590976715, Accuracy: 0.5084469472436277\n",
      "Epoch: 44, Loss_sp: 0.22465424239635468, Loss_mu: 0.12108613550662994, Loss_smr: 0.23700019717216492, Accuracy: 0.5069650266745702\n",
      "Epoch: 45, Loss_sp: 0.8207434415817261, Loss_mu: 1.0182462930679321, Loss_smr: 0.28170499205589294, Accuracy: 0.5139300533491404\n",
      "Epoch: 46, Loss_sp: 0.4981269836425781, Loss_mu: 0.16811414062976837, Loss_smr: 0.15640757977962494, Accuracy: 0.505334914048607\n",
      "Epoch: 47, Loss_sp: 0.06560654938220978, Loss_mu: 0.2987141013145447, Loss_smr: 0.1934555321931839, Accuracy: 0.5044457617071725\n",
      "Epoch: 48, Loss_sp: 0.07964906841516495, Loss_mu: 0.8190520405769348, Loss_smr: 0.321718692779541, Accuracy: 0.509484291641968\n",
      "Epoch: 49, Loss_sp: 0.20386771857738495, Loss_mu: 0.18632552027702332, Loss_smr: 0.19655002653598785, Accuracy: 0.5120035566093657\n",
      "Epoch: 50, Loss_sp: 0.12630322575569153, Loss_mu: 0.40782609581947327, Loss_smr: 0.27317914366722107, Accuracy: 0.5142264374629519\n",
      "Epoch: 51, Loss_sp: 0.3731536269187927, Loss_mu: 0.1172741949558258, Loss_smr: 0.15052050352096558, Accuracy: 0.5056312981624185\n",
      "Epoch: 52, Loss_sp: 0.006970367394387722, Loss_mu: 0.27511075139045715, Loss_smr: 0.23657916486263275, Accuracy: 0.520154119739182\n",
      "Epoch: 53, Loss_sp: 0.07317178696393967, Loss_mu: 0.2019628882408142, Loss_smr: 0.32655370235443115, Accuracy: 0.5198577356253705\n",
      "Epoch: 54, Loss_sp: 0.1394340693950653, Loss_mu: 0.1649661511182785, Loss_smr: 0.1475846767425537, Accuracy: 0.5139300533491404\n",
      "Epoch: 55, Loss_sp: 0.13180333375930786, Loss_mu: 0.32551008462905884, Loss_smr: 0.15014423429965973, Accuracy: 0.5179312388855958\n",
      "Epoch: 56, Loss_sp: 0.018658988177776337, Loss_mu: 0.06849575787782669, Loss_smr: 0.19265960156917572, Accuracy: 0.5220806164789568\n",
      "Epoch: 57, Loss_sp: 0.17330415546894073, Loss_mu: 0.6385607719421387, Loss_smr: 0.19368472695350647, Accuracy: 0.5143746295198577\n",
      "Epoch: 58, Loss_sp: 1.030474066734314, Loss_mu: 1.5869765281677246, Loss_smr: 0.23665155470371246, Accuracy: 0.5154119739181979\n",
      "Epoch: 59, Loss_sp: 0.012475513853132725, Loss_mu: 0.40040910243988037, Loss_smr: 0.23564356565475464, Accuracy: 0.5222288085358625\n",
      "Epoch: 60, Loss_sp: 0.038223959505558014, Loss_mu: 0.721898078918457, Loss_smr: 0.2355971336364746, Accuracy: 0.5179312388855958\n",
      "Epoch: 61, Loss_sp: 0.023291734978556633, Loss_mu: 0.27517449855804443, Loss_smr: 0.19322684407234192, Accuracy: 0.517190278601067\n",
      "Epoch: 62, Loss_sp: 0.10332901775836945, Loss_mu: 0.1981877237558365, Loss_smr: 0.15111775696277618, Accuracy: 0.5241553052756373\n",
      "Epoch: 63, Loss_sp: 0.011696649715304375, Loss_mu: 0.08753830194473267, Loss_smr: 0.28251001238822937, Accuracy: 0.5205986959098993\n",
      "Epoch: 64, Loss_sp: 0.029795484617352486, Loss_mu: 0.30212002992630005, Loss_smr: 0.15108223259449005, Accuracy: 0.5294902193242442\n",
      "Epoch: 65, Loss_sp: 0.04379352927207947, Loss_mu: 0.41464585065841675, Loss_smr: 0.2782686948776245, Accuracy: 0.5263781861292235\n",
      "Epoch: 66, Loss_sp: 0.08812466263771057, Loss_mu: 0.9259266257286072, Loss_smr: 0.19288812577724457, Accuracy: 0.521339656194428\n",
      "Epoch: 67, Loss_sp: 0.11617401242256165, Loss_mu: 0.6369978189468384, Loss_smr: 0.14610238373279572, Accuracy: 0.522525192649674\n",
      "Epoch: 68, Loss_sp: 0.10428404808044434, Loss_mu: 0.2647008001804352, Loss_smr: 0.278400182723999, Accuracy: 0.532602252519265\n",
      "Epoch: 69, Loss_sp: 0.04438622295856476, Loss_mu: 0.1067514419555664, Loss_smr: 0.15316957235336304, Accuracy: 0.52371072910492\n",
      "Epoch: 70, Loss_sp: 0.37967032194137573, Loss_mu: 0.258920818567276, Loss_smr: 0.14825144410133362, Accuracy: 0.5259336099585062\n",
      "Epoch: 71, Loss_sp: 0.0053537385538220406, Loss_mu: 0.2427351474761963, Loss_smr: 0.23565344512462616, Accuracy: 0.5291938352104327\n",
      "Epoch: 72, Loss_sp: 0.11506857722997665, Loss_mu: 0.06852470338344574, Loss_smr: 0.1929154396057129, Accuracy: 0.524896265560166\n",
      "Epoch: 73, Loss_sp: 0.3699191212654114, Loss_mu: 0.5063562989234924, Loss_smr: 0.19478359818458557, Accuracy: 0.5277119146413752\n",
      "Epoch: 74, Loss_sp: 0.4993245303630829, Loss_mu: 0.29050329327583313, Loss_smr: 0.1986207365989685, Accuracy: 0.530823947836396\n",
      "Epoch: 75, Loss_sp: 0.004065620247274637, Loss_mu: 0.34904834628105164, Loss_smr: 0.32324326038360596, Accuracy: 0.5234143449911085\n",
      "Epoch: 76, Loss_sp: 0.3116166293621063, Loss_mu: 0.20629259943962097, Loss_smr: 0.23563340306282043, Accuracy: 0.523117960877297\n",
      "Epoch: 77, Loss_sp: 0.12486329674720764, Loss_mu: 0.5010483264923096, Loss_smr: 0.27483513951301575, Accuracy: 0.529045643153527\n",
      "Epoch: 78, Loss_sp: 0.11433912068605423, Loss_mu: 0.09895466268062592, Loss_smr: 0.15539902448654175, Accuracy: 0.5268227622999407\n",
      "Epoch: 79, Loss_sp: 0.10199185460805893, Loss_mu: 0.1468074768781662, Loss_smr: 0.23575550317764282, Accuracy: 0.5367516301126259\n",
      "Epoch: 80, Loss_sp: 0.03766275942325592, Loss_mu: 0.4109733998775482, Loss_smr: 0.19370540976524353, Accuracy: 0.5265263781861292\n",
      "Epoch: 81, Loss_sp: 0.05374683439731598, Loss_mu: 0.1002098098397255, Loss_smr: 0.23791912198066711, Accuracy: 0.5312685240071132\n",
      "Epoch: 82, Loss_sp: 0.20935550332069397, Loss_mu: 0.1794988065958023, Loss_smr: 0.15211117267608643, Accuracy: 0.5315649081209247\n",
      "Epoch: 83, Loss_sp: 0.004941090010106564, Loss_mu: 0.4604533314704895, Loss_smr: 0.1959909349679947, Accuracy: 0.533787788974511\n",
      "Epoch: 84, Loss_sp: 0.09931455552577972, Loss_mu: 0.29642435908317566, Loss_smr: 0.2365696132183075, Accuracy: 0.525489033787789\n",
      "Epoch: 85, Loss_sp: 0.10597621649503708, Loss_mu: 0.3471388816833496, Loss_smr: 0.1948537528514862, Accuracy: 0.5354179016004742\n",
      "Epoch: 86, Loss_sp: 0.0018213210860267282, Loss_mu: 0.5845110416412354, Loss_smr: 0.1555405706167221, Accuracy: 0.5299347954949615\n",
      "Epoch: 87, Loss_sp: 1.2867610454559326, Loss_mu: 4.384986877441406, Loss_smr: 0.10557664185762405, Accuracy: 0.5363070539419087\n",
      "Epoch: 88, Loss_sp: 0.026725202798843384, Loss_mu: 0.24620279669761658, Loss_smr: 0.15220080316066742, Accuracy: 0.5380853586247777\n",
      "Epoch: 89, Loss_sp: 0.5156785845756531, Loss_mu: 0.3610740303993225, Loss_smr: 0.237204447388649, Accuracy: 0.5342323651452282\n",
      "Epoch: 90, Loss_sp: 0.055538687855005264, Loss_mu: 0.2691245675086975, Loss_smr: 0.19500266015529633, Accuracy: 0.527267338470658\n",
      "Epoch: 91, Loss_sp: 0.06990907341241837, Loss_mu: 0.5301470756530762, Loss_smr: 0.14756828546524048, Accuracy: 0.5389745109662122\n",
      "Epoch: 92, Loss_sp: 0.6897364854812622, Loss_mu: 0.14115798473358154, Loss_smr: 0.15061543881893158, Accuracy: 0.534380557202134\n",
      "Epoch: 93, Loss_sp: 0.0928473100066185, Loss_mu: 0.08818255364894867, Loss_smr: 0.23512157797813416, Accuracy: 0.5336395969176052\n",
      "Epoch: 94, Loss_sp: 0.05749302729964256, Loss_mu: 0.5303348898887634, Loss_smr: 0.1553577035665512, Accuracy: 0.528452874925904\n",
      "Epoch: 95, Loss_sp: 0.3350624144077301, Loss_mu: 0.14217041432857513, Loss_smr: 0.10553223639726639, Accuracy: 0.5277119146413752\n",
      "Epoch: 96, Loss_sp: 0.04298701882362366, Loss_mu: 0.5321062207221985, Loss_smr: 0.2783926725387573, Accuracy: 0.5367516301126259\n",
      "Epoch: 97, Loss_sp: 0.07485216110944748, Loss_mu: 0.64903324842453, Loss_smr: 0.3297373056411743, Accuracy: 0.5321576763485477\n",
      "Epoch: 98, Loss_sp: 0.030167443677783012, Loss_mu: 0.16145367920398712, Loss_smr: 0.1939563751220703, Accuracy: 0.5380853586247777\n",
      "Epoch: 99, Loss_sp: 1.543431282043457, Loss_mu: 0.8561995029449463, Loss_smr: 0.2362738698720932, Accuracy: 0.536158861885003\n",
      "Epoch: 100, Loss_sp: 0.04680952429771423, Loss_mu: 0.17529796063899994, Loss_smr: 0.19629037380218506, Accuracy: 0.534973325429757\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "print(\"model_init\")\n",
    "model = MtlCascadeModel(hp)\n",
    "# print(model)\n",
    "loss_sp = nn.BCEWithLogitsLoss()\n",
    "loss_mu = nn.BCEWithLogitsLoss()\n",
    "loss_smr = nn.MSELoss()\n",
    "\n",
    "out_dict = {\"speech\": [1, 0, 0, 0], \"music\": [0, 1, 0, 0], \"mixture\": [0, 0, 1, 1]}\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = Adam(model.parameters(), lr=0.002)\n",
    "# optimizer = SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.1)\n",
    "\n",
    "print(\"start_training\")\n",
    "for epoch in range(1,hp[\"n_epochs\"]+1):\n",
    "    train(\n",
    "        train_loader, model, epoch, out_dict, loss_sp, loss_mu, loss_smr, optimizer\n",
    "    )\n",
    "# train(\n",
    "#     train_loader, model, hp[\"n_epochs\"], out_dict, loss_sp, loss_mu, loss_smr, optimizer\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the classical fourier trasformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Load audio file\n",
    "y, sr = librosa.load('audio_file.wav')\n",
    "\n",
    "# Perform HPSS\n",
    "harmonic, percussive = librosa.effects.hpss(y)\n",
    "\n",
    "# Save the harmonic and percussive components\n",
    "librosa.output.write_wav('harmonic.wav', harmonic, sr)\n",
    "librosa.output.write_wav('percussive.wav', percussive, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute skewness\n",
    "def compute_skewness(matrix):\n",
    "    return np.mean(((matrix - np.mean(matrix, axis=0)) / np.std(matrix, axis=0)) ** 3, axis=0)\n",
    "def hpss_classification (speech,music,mixture,sr):\n",
    "    # Perform HPSS\n",
    "    harmonic_speech, percussive_speech = librosa.effects.hpss(speech)\n",
    "    harmonic_music, percussive_music = librosa.effects.hpss(music)\n",
    "    harmonic_mixture, percussive_mixture = librosa.effects.hpss(mixture)\n",
    "\n",
    "    # Compute skewness vectors\n",
    "    skewness_speech = compute_skewness(harmonic_speech) + compute_skewness(percussive_speech)\n",
    "    skewness_music = compute_skewness(harmonic_music) + compute_skewness(percussive_music)\n",
    "    skewness_mixture = compute_skewness(harmonic_mixture) + compute_skewness(percussive_mixture)\n",
    "\n",
    "    # Concatenate skewness vectors for t-SNE\n",
    "    all_skewness = np.vstack((skewness_speech, skewness_music, skewness_mixture))\n",
    "\n",
    "    # Apply t-SNE for dimensionality reduction\n",
    "    # tsne = TSNE(n_components=2,perplexity=2, random_state=0)\n",
    "    # reduced_skewness = tsne.fit_transform(all_skewness)\n",
    "    reduced_skewness = all_skewness\n",
    "    # Plot the results\n",
    "    print( reduced_skewness.shape)\n",
    "    plt.scatter(reduced_skewness[:1, 0], [0], label='Speech')\n",
    "    plt.scatter(reduced_skewness[1:2, 0], [0], label='Music')\n",
    "    plt.scatter(reduced_skewness[2:, 0], [0]*len(reduced_skewness[2:, 0]), label='Mixture')\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE Visualization of Class Separability')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_data\n",
    "import pandas as pd\n",
    "from param import dataset_path, sample_universe_size\n",
    "combination_paths = prepare_data(f\".{dataset_path}\")\n",
    "sampled_df = combination_paths.sample(\n",
    "    frac=sample_universe_size, random_state=42, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/musan/music/jamendo/music-jamendo-0169...</td>\n",
       "      <td>../data/musan/speech/librivox/speech-librivox-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/musan/music/fma/music-fma-0042.wav</td>\n",
       "      <td>../data/musan/speech/librivox/speech-librivox-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/musan/music/jamendo/music-jamendo-0146...</td>\n",
       "      <td>../data/musan/speech/us-gov/speech-us-gov-0023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/musan/music/fma/music-fma-0023.wav</td>\n",
       "      <td>../data/musan/speech/us-gov/speech-us-gov-0018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/musan/music/jamendo/music-jamendo-0212...</td>\n",
       "      <td>../data/musan/speech/librivox/speech-librivox-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               music  \\\n",
       "0  ../data/musan/music/jamendo/music-jamendo-0169...   \n",
       "1         ../data/musan/music/fma/music-fma-0042.wav   \n",
       "2  ../data/musan/music/jamendo/music-jamendo-0146...   \n",
       "3         ../data/musan/music/fma/music-fma-0023.wav   \n",
       "4  ../data/musan/music/jamendo/music-jamendo-0212...   \n",
       "\n",
       "                                              speech  \n",
       "0  ../data/musan/speech/librivox/speech-librivox-...  \n",
       "1  ../data/musan/speech/librivox/speech-librivox-...  \n",
       "2  ../data/musan/speech/us-gov/speech-us-gov-0023...  \n",
       "3  ../data/musan/speech/us-gov/speech-us-gov-0018...  \n",
       "4  ../data/musan/speech/librivox/speech-librivox-...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iteration Category data_type   Min   Max  Mean  Median   STD\n",
      "0             0   Speech  harmonic -0.57  0.55 -0.00    0.00  0.10\n",
      "1             0    Music  harmonic -0.62  0.60 -0.00    0.00  0.14\n",
      "2             0  Mixture  harmonic -0.34  0.34 -0.00   -0.00  0.07\n",
      "3             0   Speech  skewness -0.07 -0.07 -0.07   -0.07  0.00\n",
      "4             0    Music  skewness -0.00 -0.00 -0.00   -0.00  0.00\n",
      "...         ...      ...       ...   ...   ...   ...     ...   ...\n",
      "1681        280    Music  harmonic -0.50  0.44 -0.00    0.00  0.09\n",
      "1682        280  Mixture  harmonic -0.25  0.24 -0.00    0.00  0.06\n",
      "1683        280   Speech  skewness  0.41  0.41  0.41    0.41  0.00\n",
      "1684        280    Music  skewness -0.08 -0.08 -0.08   -0.08  0.00\n",
      "1685        280  Mixture  skewness -0.02 -0.02 -0.02   -0.02  0.00\n",
      "\n",
      "[1686 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from utils import load_audio,load_music,mix_signals\n",
    "from param import sampling_rate\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['Iteration', 'Category','data_type', 'Min', 'Max', 'Mean', 'Median', 'STD'])\n",
    "list_data =[]\n",
    "for i in range(281):\n",
    "    # print(sampled_df.iloc[i][\"speech\"])\n",
    "    # print(sampled_df.iloc[i][\"music\"])\n",
    "\n",
    "    speech_wave = load_music(sampled_df.iloc[i][\"speech\"])\n",
    "    music_wave = load_music(sampled_df.iloc[i][\"music\"])\n",
    "    mixed_wave = mix_signals(sampled_df.iloc[i][\"speech\"],sampled_df.iloc[0][\"music\"])\n",
    "    #hpss_classification(speech_wave,music_wave,mixed_wave,sampling_rate)\n",
    "    harmonic_speech, percussive_speech = librosa.effects.hpss(speech_wave)\n",
    "    harmonic_music, percussive_music = librosa.effects.hpss(music_wave)\n",
    "    harmonic_mixture, percussive_mixture = librosa.effects.hpss(mixed_wave)\n",
    "    # plot_fig(harmonic_speech,percussive_speech,\"speech\")\n",
    "    # plot_fig(harmonic_music,percussive_music,\"music\")\n",
    "    # plot_fig(harmonic_mixture,percussive_mixture,\"mixture\")\n",
    "    for type_data in [\"harmonic\", \"skewness\"]:\n",
    "        if type_data == \"harmonic\":\n",
    "            data_speech = harmonic_speech\n",
    "            data_music = harmonic_music\n",
    "            data_mixture = harmonic_mixture\n",
    "        else:\n",
    "            data_speech = compute_skewness(harmonic_speech)\n",
    "            data_music = compute_skewness(harmonic_music)\n",
    "            data_mixture = compute_skewness(harmonic_mixture)\n",
    "\n",
    "    \n",
    "    # data_speech = np.abs(harmonic_speech- percussive_speech)\n",
    "    # data_music = np.abs(harmonic_music- percussive_music)\n",
    "    # data_mixture = np.abs(harmonic_mixture- percussive_mixture)\n",
    "    # # Append the data for each category to the DataFrame\n",
    "        list_data.append({\n",
    "            'Iteration': i,\n",
    "            'Category': 'Speech',\n",
    "            'data_type': type_data,\n",
    "            'Min': round(np.min(data_speech),2),\n",
    "            'Max': round(np.max(data_speech),2),\n",
    "            'Mean': round(np.mean(data_speech),2),\n",
    "            'Median': round(np.median(data_speech),2),\n",
    "            'STD': round(np.std(data_speech),2),\n",
    "        })\n",
    "        \n",
    "        list_data.append({\n",
    "            'Iteration': i,\n",
    "            'Category': 'Music',\n",
    "            'data_type': type_data,\n",
    "            'Min': round(np.min(data_music),2),\n",
    "            'Max': round(np.max(data_music),2),\n",
    "            'Mean': round(np.mean(data_music),2),\n",
    "            'Median': round(np.median(data_music),2),\n",
    "            'STD': round(np.std(data_music),2),\n",
    "        })\n",
    "        \n",
    "        list_data.append({\n",
    "            'Iteration': i,\n",
    "            'Category': 'Mixture',\n",
    "            'data_type': type_data,\n",
    "            'Min': round(np.min(data_mixture),2),\n",
    "            'Max': round(np.max(data_mixture),2),\n",
    "            'Mean': round(np.mean(data_mixture),2),\n",
    "            'Median': round(np.median(data_mixture),2),\n",
    "            'STD': round(np.std(data_mixture),2),\n",
    "        })\n",
    "\n",
    "# Print the DataFrame\n",
    "df = pd.DataFrame(list_data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "    # speech_classification = classify_waveform(speech_wave, sampling_rate)\n",
    "    # music_classification = classify_waveform(music_wave, sampling_rate)\n",
    "    # mixed_classification = classify_waveform(mixed_wave, sampling_rate)\n",
    "    # print(f\"Ground Truth: Speech, Predicted: {speech_classification}\")\n",
    "    # print(f\"Ground Truth: Music, Predicted: {music_classification}\")\n",
    "    # print(f\"Ground Truth: Mixed, Predicted: {mixed_classification}\")\n",
    "    # print(\"------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Category', ascending=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('hpss_classification_sk.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iteration Category   data_type   Min   Max  Mean  Median   STD\n",
      "14          2  Mixture    harmonic -0.34  0.36   0.0     0.0  0.07\n",
      "26          4  Mixture    harmonic -0.31  0.31  -0.0     0.0  0.07\n",
      "23          3  Mixture  percussive -0.23  0.35   0.0     0.0  0.04\n",
      "20          3  Mixture    harmonic -0.33  0.37   0.0     0.0  0.07\n",
      "17          2  Mixture  percussive -0.41  0.43  -0.0     0.0  0.08\n",
      "11          1  Mixture  percussive -0.39  0.41   0.0     0.0  0.08\n",
      "8           1  Mixture    harmonic -0.29  0.24  -0.0     0.0  0.06\n",
      "29          4  Mixture  percussive -0.44  0.40  -0.0    -0.0  0.07\n",
      "5           0  Mixture  percussive -0.42  0.44   0.0     0.0  0.10\n",
      "2           0  Mixture    harmonic -0.27  0.27  -0.0    -0.0  0.06\n",
      "10          1    Music  percussive -0.01  0.01   0.0     0.0  0.00\n",
      "1           0    Music    harmonic -0.41  0.40  -0.0     0.0  0.08\n",
      "13          2    Music    harmonic -0.80  0.82   0.0    -0.0  0.25\n",
      "28          4    Music  percussive -0.49  0.49   0.0     0.0  0.07\n",
      "25          4    Music    harmonic -0.22  0.16   0.0     0.0  0.05\n",
      "16          2    Music  percussive -0.83  0.76   0.0    -0.0  0.13\n",
      "4           0    Music  percussive -0.82  0.90  -0.0    -0.0  0.15\n",
      "7           1    Music    harmonic -0.01  0.01   0.0     0.0  0.00\n",
      "19          3    Music    harmonic -0.37  0.32  -0.0    -0.0  0.10\n",
      "22          3    Music  percussive -0.21  0.19  -0.0    -0.0  0.02\n",
      "6           1   Speech    harmonic -0.27  0.22   0.0     0.0  0.04\n",
      "27          4   Speech  percussive -0.29  0.25  -0.0    -0.0  0.04\n",
      "24          4   Speech    harmonic -0.53  0.48  -0.0     0.0  0.09\n",
      "18          3   Speech    harmonic -0.42  0.44   0.0     0.0  0.07\n",
      "3           0   Speech  percussive -0.26  0.32   0.0    -0.0  0.04\n",
      "15          2   Speech  percussive -0.18  0.15   0.0     0.0  0.02\n",
      "12          2   Speech    harmonic -0.11  0.11   0.0    -0.0  0.01\n",
      "9           1   Speech  percussive -0.74  0.77  -0.0     0.0  0.07\n",
      "21          3   Speech  percussive -0.81  0.57   0.0     0.0  0.08\n",
      "0           0   Speech    harmonic -0.41  0.38   0.0    -0.0  0.06\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming harmonic_speech and percussive_speech are numpy arrays\n",
    "# representing the harmonic and percussive components of your speech signal\n",
    "def plot_fig(harmonic, persussive, class_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(harmonic)\n",
    "    plt.title(f'Harmonic Component of {class_name}')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(persussive)\n",
    "    plt.title(f'Percussive Component of {class_name}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.groupby(['Category','data_type']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional_classification(signal_wave):\n",
    "    # Perform HPSS\n",
    "    harmonic, percussive = librosa.effects.hpss(signal_wave)\n",
    "\n",
    "    # Compute skewness vectors\n",
    "    skewness = compute_skewness(harmonic) + compute_skewness(percussive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('hpss_classification_grp_sk.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
