{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_loader\n"
     ]
    }
   ],
   "source": [
    "from dataloader import dataloader, SignalDataset\n",
    "from utils import prepare_data\n",
    "from param import dataset_path, sample_universe_size\n",
    "from torch.utils.data import ConcatDataset\n",
    "from MTL_w_cascade_info import MtlCascadeModel\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch\n",
    "\n",
    "# from torch.nn.utils import weight_norm\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "hp = {\n",
    "    \"n_layers\": 1,\n",
    "    \"sp_hidden_nodes\": 20,\n",
    "    \"n_sp_hidden_lyrs\": 1,\n",
    "    \"mu_hidden_nodes\": 20,\n",
    "    \"n_mu_hidden_lyrs\": 1,\n",
    "    \"smr_hidden_nodes\": 20,\n",
    "    \"n_smr_hidden_lyrs\": 1,\n",
    "    \"n_epochs\": 100,\n",
    "    \"batch_size\": 20,\n",
    "    \"train_ratio\": 0.8,\n",
    "}\n",
    "combined_dataset = torch.load('dataset.pth')\n",
    "print(\"data_loader\")\n",
    "train_loader, test_loader = dataloader(\n",
    "    datasets=combined_dataset,\n",
    "    train_ratio=hp[\"train_ratio\"],\n",
    "    train_batch_size=hp[\"batch_size\"],\n",
    "    test_batch_size=1,\n",
    ")\n",
    "\n",
    "def train(\n",
    "    train_loader,\n",
    "    model,\n",
    "    epoch,\n",
    "    out_dict,\n",
    "    loss_sp_fn,\n",
    "    loss_mu_fn,\n",
    "    loss_smr_fn,\n",
    "    optimizer,\n",
    "):\n",
    "    correct = 0\n",
    "    for data in train_loader:\n",
    "        feature, label = data\n",
    "        y = [out_dict[x] for x in label]\n",
    "        out_sp, out_mu, out_smr = model(feature)\n",
    "\n",
    "        sp_list = [inner_list[0] for inner_list in y]\n",
    "        mu_list = [inner_list[1] for inner_list in y]\n",
    "        smr_list = [inner_list[2:] for inner_list in y]\n",
    "        y_sp = torch.Tensor(sp_list).unsqueeze(1)\n",
    "        y_mu = torch.Tensor(mu_list).unsqueeze(1)\n",
    "        y_smr = torch.Tensor(smr_list).unsqueeze(1)\n",
    "\n",
    "        loss_sp = loss_sp_fn(out_sp, y_sp)\n",
    "        loss_mu = loss_mu_fn(out_mu, y_mu)\n",
    "        loss_smr = loss_smr_fn(out_smr, y_smr)\n",
    "\n",
    "        total_loss = loss_sp + loss_mu + loss_smr\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred_y = torch.cat((out_sp, out_mu, out_smr), dim=1)\n",
    "        result = (pred_y > 0.5).float()\n",
    "        target = torch.tensor(y).float()\n",
    "        for i in range(result.size(0)):\n",
    "            if torch.all(torch.eq(result[i], target[i])):\n",
    "                correct += 1\n",
    "    accuracy = correct / len(train_loader.dataset)\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, Loss_sp: {loss_sp}, Loss_mu: {loss_mu}, Loss_smr: {loss_smr}, Accuracy: {accuracy}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_init\n",
      "start_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateeks/projects/iitj/su/Speech-Understanding-Minor/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([20, 1, 2])) that is different to the input size (torch.Size([20, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prateeks/projects/iitj/su/Speech-Understanding-Minor/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8, 1, 2])) that is different to the input size (torch.Size([8, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss_sp: 0.5497570037841797, Loss_mu: 1.669691562652588, Loss_smr: 0.08134792745113373, Accuracy: 0.22821576763485477\n",
      "Epoch: 2, Loss_sp: 0.12731775641441345, Loss_mu: 0.3549463748931885, Loss_smr: 0.1975173056125641, Accuracy: 0.36751630112625966\n",
      "Epoch: 3, Loss_sp: 0.13728009164333344, Loss_mu: 0.4615171551704407, Loss_smr: 0.19479364156723022, Accuracy: 0.4013040901007706\n",
      "Epoch: 4, Loss_sp: 0.18401402235031128, Loss_mu: 0.39979904890060425, Loss_smr: 0.3128724694252014, Accuracy: 0.41567871962062836\n",
      "Epoch: 5, Loss_sp: 0.07096236944198608, Loss_mu: 0.4647606313228607, Loss_smr: 0.23608353734016418, Accuracy: 0.40915826911677533\n",
      "Epoch: 6, Loss_sp: 0.35188257694244385, Loss_mu: 0.545046865940094, Loss_smr: 0.19359494745731354, Accuracy: 0.43375815056312983\n",
      "Epoch: 7, Loss_sp: 0.19236329197883606, Loss_mu: 0.5008758902549744, Loss_smr: 0.2694648802280426, Accuracy: 0.4350918790752816\n",
      "Epoch: 8, Loss_sp: 1.4852579832077026, Loss_mu: 0.21463799476623535, Loss_smr: 0.15860165655612946, Accuracy: 0.4460580912863071\n",
      "Epoch: 9, Loss_sp: 0.7786109447479248, Loss_mu: 1.4333815574645996, Loss_smr: 0.2365739941596985, Accuracy: 0.44101956135151155\n",
      "Epoch: 10, Loss_sp: 0.45253580808639526, Loss_mu: 0.7057640552520752, Loss_smr: 0.23522034287452698, Accuracy: 0.45583876704208653\n",
      "Epoch: 11, Loss_sp: 0.39727020263671875, Loss_mu: 0.44263607263565063, Loss_smr: 0.23619888722896576, Accuracy: 0.45643153526970953\n",
      "Epoch: 12, Loss_sp: 0.6125422716140747, Loss_mu: 1.2083640098571777, Loss_smr: 0.28254109621047974, Accuracy: 0.46680497925311204\n",
      "Epoch: 13, Loss_sp: 0.08395571261644363, Loss_mu: 1.084690809249878, Loss_smr: 0.14721539616584778, Accuracy: 0.46828689982216953\n",
      "Epoch: 14, Loss_sp: 0.09495381265878677, Loss_mu: 0.25495126843452454, Loss_smr: 0.15970373153686523, Accuracy: 0.4718435091879075\n",
      "Epoch: 15, Loss_sp: 0.0698404386639595, Loss_mu: 0.18575160205364227, Loss_smr: 0.11056943237781525, Accuracy: 0.4788085358624778\n",
      "Epoch: 16, Loss_sp: 0.04318779334425926, Loss_mu: 0.7130489349365234, Loss_smr: 0.15028204023838043, Accuracy: 0.47347362181387076\n",
      "Epoch: 17, Loss_sp: 0.0818684846162796, Loss_mu: 0.27545076608657837, Loss_smr: 0.19290493428707123, Accuracy: 0.48651452282157676\n",
      "Epoch: 18, Loss_sp: 0.1725568026304245, Loss_mu: 0.4179637134075165, Loss_smr: 0.23797300457954407, Accuracy: 0.46799051570835803\n",
      "Epoch: 19, Loss_sp: 0.1919795572757721, Loss_mu: 0.3622596263885498, Loss_smr: 0.1918148696422577, Accuracy: 0.472732661529342\n",
      "Epoch: 20, Loss_sp: 0.07556981593370438, Loss_mu: 0.18951784074306488, Loss_smr: 0.1937735229730606, Accuracy: 0.4791049199762893\n",
      "Epoch: 21, Loss_sp: 0.056652434170246124, Loss_mu: 0.3204583525657654, Loss_smr: 0.23690558969974518, Accuracy: 0.4842916419679905\n",
      "Epoch: 22, Loss_sp: 0.06018221378326416, Loss_mu: 0.09107986092567444, Loss_smr: 0.23660966753959656, Accuracy: 0.4854771784232365\n",
      "Epoch: 23, Loss_sp: 0.06560888886451721, Loss_mu: 0.3257613480091095, Loss_smr: 0.32533442974090576, Accuracy: 0.4842916419679905\n",
      "Epoch: 24, Loss_sp: 0.10355797410011292, Loss_mu: 0.15672357380390167, Loss_smr: 0.23507201671600342, Accuracy: 0.485773562537048\n",
      "Epoch: 25, Loss_sp: 0.49295443296432495, Loss_mu: 0.532962441444397, Loss_smr: 0.23693539202213287, Accuracy: 0.48295791345583877\n",
      "Epoch: 26, Loss_sp: 0.002992207184433937, Loss_mu: 0.35979998111724854, Loss_smr: 0.15272091329097748, Accuracy: 0.4890337877889745\n",
      "Epoch: 27, Loss_sp: 0.9586302638053894, Loss_mu: 0.2806282341480255, Loss_smr: 0.19513411819934845, Accuracy: 0.4884410195613515\n",
      "Epoch: 28, Loss_sp: 0.030592553317546844, Loss_mu: 0.49703091382980347, Loss_smr: 0.23568610846996307, Accuracy: 0.4949614700652045\n",
      "Epoch: 29, Loss_sp: 0.3449230492115021, Loss_mu: 0.3887611925601959, Loss_smr: 0.19349335134029388, Accuracy: 0.4927385892116183\n",
      "Epoch: 30, Loss_sp: 0.044806528836488724, Loss_mu: 0.502322256565094, Loss_smr: 0.23655974864959717, Accuracy: 0.49155305275637223\n",
      "Epoch: 31, Loss_sp: 0.0604616180062294, Loss_mu: 0.2117225080728531, Loss_smr: 0.15220046043395996, Accuracy: 0.5001481920569057\n",
      "Epoch: 32, Loss_sp: 0.027247650548815727, Loss_mu: 0.8172510862350464, Loss_smr: 0.27797266840934753, Accuracy: 0.49688796680497926\n",
      "Epoch: 33, Loss_sp: 0.023280655965209007, Loss_mu: 0.4211570918560028, Loss_smr: 0.193600133061409, Accuracy: 0.5056312981624185\n",
      "Epoch: 34, Loss_sp: 0.0258139930665493, Loss_mu: 0.9352917671203613, Loss_smr: 0.1279202401638031, Accuracy: 0.4979253112033195\n",
      "Epoch: 35, Loss_sp: 0.26903030276298523, Loss_mu: 0.2337425947189331, Loss_smr: 0.27614015340805054, Accuracy: 0.495257854179016\n",
      "Epoch: 36, Loss_sp: 0.1445968896150589, Loss_mu: 0.44997668266296387, Loss_smr: 0.19494003057479858, Accuracy: 0.499407231772377\n",
      "Epoch: 37, Loss_sp: 1.4519846439361572, Loss_mu: 0.6738405227661133, Loss_smr: 0.19234758615493774, Accuracy: 0.5105216360403082\n",
      "Epoch: 38, Loss_sp: 0.10961218178272247, Loss_mu: 0.23489254713058472, Loss_smr: 0.19271647930145264, Accuracy: 0.5026674570243035\n",
      "Epoch: 39, Loss_sp: 0.3239405155181885, Loss_mu: 0.22391264140605927, Loss_smr: 0.19444876909255981, Accuracy: 0.5072614107883817\n",
      "Epoch: 40, Loss_sp: 0.02873827889561653, Loss_mu: 0.21354258060455322, Loss_smr: 0.19468092918395996, Accuracy: 0.5026674570243035\n",
      "Epoch: 41, Loss_sp: 0.6267442107200623, Loss_mu: 0.3553236424922943, Loss_smr: 0.3155795633792877, Accuracy: 0.502371072910492\n",
      "Epoch: 42, Loss_sp: 0.012759498320519924, Loss_mu: 0.4984821081161499, Loss_smr: 0.32118529081344604, Accuracy: 0.5038529934795495\n",
      "Epoch: 43, Loss_sp: 1.040339469909668, Loss_mu: 0.19904229044914246, Loss_smr: 0.19458116590976715, Accuracy: 0.5084469472436277\n",
      "Epoch: 44, Loss_sp: 0.22465424239635468, Loss_mu: 0.12108613550662994, Loss_smr: 0.23700019717216492, Accuracy: 0.5069650266745702\n",
      "Epoch: 45, Loss_sp: 0.8207434415817261, Loss_mu: 1.0182462930679321, Loss_smr: 0.28170499205589294, Accuracy: 0.5139300533491404\n",
      "Epoch: 46, Loss_sp: 0.4981269836425781, Loss_mu: 0.16811414062976837, Loss_smr: 0.15640757977962494, Accuracy: 0.505334914048607\n",
      "Epoch: 47, Loss_sp: 0.06560654938220978, Loss_mu: 0.2987141013145447, Loss_smr: 0.1934555321931839, Accuracy: 0.5044457617071725\n",
      "Epoch: 48, Loss_sp: 0.07964906841516495, Loss_mu: 0.8190520405769348, Loss_smr: 0.321718692779541, Accuracy: 0.509484291641968\n",
      "Epoch: 49, Loss_sp: 0.20386771857738495, Loss_mu: 0.18632552027702332, Loss_smr: 0.19655002653598785, Accuracy: 0.5120035566093657\n",
      "Epoch: 50, Loss_sp: 0.12630322575569153, Loss_mu: 0.40782609581947327, Loss_smr: 0.27317914366722107, Accuracy: 0.5142264374629519\n",
      "Epoch: 51, Loss_sp: 0.3731536269187927, Loss_mu: 0.1172741949558258, Loss_smr: 0.15052050352096558, Accuracy: 0.5056312981624185\n",
      "Epoch: 52, Loss_sp: 0.006970367394387722, Loss_mu: 0.27511075139045715, Loss_smr: 0.23657916486263275, Accuracy: 0.520154119739182\n",
      "Epoch: 53, Loss_sp: 0.07317178696393967, Loss_mu: 0.2019628882408142, Loss_smr: 0.32655370235443115, Accuracy: 0.5198577356253705\n",
      "Epoch: 54, Loss_sp: 0.1394340693950653, Loss_mu: 0.1649661511182785, Loss_smr: 0.1475846767425537, Accuracy: 0.5139300533491404\n",
      "Epoch: 55, Loss_sp: 0.13180333375930786, Loss_mu: 0.32551008462905884, Loss_smr: 0.15014423429965973, Accuracy: 0.5179312388855958\n",
      "Epoch: 56, Loss_sp: 0.018658988177776337, Loss_mu: 0.06849575787782669, Loss_smr: 0.19265960156917572, Accuracy: 0.5220806164789568\n",
      "Epoch: 57, Loss_sp: 0.17330415546894073, Loss_mu: 0.6385607719421387, Loss_smr: 0.19368472695350647, Accuracy: 0.5143746295198577\n",
      "Epoch: 58, Loss_sp: 1.030474066734314, Loss_mu: 1.5869765281677246, Loss_smr: 0.23665155470371246, Accuracy: 0.5154119739181979\n",
      "Epoch: 59, Loss_sp: 0.012475513853132725, Loss_mu: 0.40040910243988037, Loss_smr: 0.23564356565475464, Accuracy: 0.5222288085358625\n",
      "Epoch: 60, Loss_sp: 0.038223959505558014, Loss_mu: 0.721898078918457, Loss_smr: 0.2355971336364746, Accuracy: 0.5179312388855958\n",
      "Epoch: 61, Loss_sp: 0.023291734978556633, Loss_mu: 0.27517449855804443, Loss_smr: 0.19322684407234192, Accuracy: 0.517190278601067\n",
      "Epoch: 62, Loss_sp: 0.10332901775836945, Loss_mu: 0.1981877237558365, Loss_smr: 0.15111775696277618, Accuracy: 0.5241553052756373\n",
      "Epoch: 63, Loss_sp: 0.011696649715304375, Loss_mu: 0.08753830194473267, Loss_smr: 0.28251001238822937, Accuracy: 0.5205986959098993\n",
      "Epoch: 64, Loss_sp: 0.029795484617352486, Loss_mu: 0.30212002992630005, Loss_smr: 0.15108223259449005, Accuracy: 0.5294902193242442\n",
      "Epoch: 65, Loss_sp: 0.04379352927207947, Loss_mu: 0.41464585065841675, Loss_smr: 0.2782686948776245, Accuracy: 0.5263781861292235\n",
      "Epoch: 66, Loss_sp: 0.08812466263771057, Loss_mu: 0.9259266257286072, Loss_smr: 0.19288812577724457, Accuracy: 0.521339656194428\n",
      "Epoch: 67, Loss_sp: 0.11617401242256165, Loss_mu: 0.6369978189468384, Loss_smr: 0.14610238373279572, Accuracy: 0.522525192649674\n",
      "Epoch: 68, Loss_sp: 0.10428404808044434, Loss_mu: 0.2647008001804352, Loss_smr: 0.278400182723999, Accuracy: 0.532602252519265\n",
      "Epoch: 69, Loss_sp: 0.04438622295856476, Loss_mu: 0.1067514419555664, Loss_smr: 0.15316957235336304, Accuracy: 0.52371072910492\n",
      "Epoch: 70, Loss_sp: 0.37967032194137573, Loss_mu: 0.258920818567276, Loss_smr: 0.14825144410133362, Accuracy: 0.5259336099585062\n",
      "Epoch: 71, Loss_sp: 0.0053537385538220406, Loss_mu: 0.2427351474761963, Loss_smr: 0.23565344512462616, Accuracy: 0.5291938352104327\n",
      "Epoch: 72, Loss_sp: 0.11506857722997665, Loss_mu: 0.06852470338344574, Loss_smr: 0.1929154396057129, Accuracy: 0.524896265560166\n",
      "Epoch: 73, Loss_sp: 0.3699191212654114, Loss_mu: 0.5063562989234924, Loss_smr: 0.19478359818458557, Accuracy: 0.5277119146413752\n",
      "Epoch: 74, Loss_sp: 0.4993245303630829, Loss_mu: 0.29050329327583313, Loss_smr: 0.1986207365989685, Accuracy: 0.530823947836396\n",
      "Epoch: 75, Loss_sp: 0.004065620247274637, Loss_mu: 0.34904834628105164, Loss_smr: 0.32324326038360596, Accuracy: 0.5234143449911085\n",
      "Epoch: 76, Loss_sp: 0.3116166293621063, Loss_mu: 0.20629259943962097, Loss_smr: 0.23563340306282043, Accuracy: 0.523117960877297\n",
      "Epoch: 77, Loss_sp: 0.12486329674720764, Loss_mu: 0.5010483264923096, Loss_smr: 0.27483513951301575, Accuracy: 0.529045643153527\n",
      "Epoch: 78, Loss_sp: 0.11433912068605423, Loss_mu: 0.09895466268062592, Loss_smr: 0.15539902448654175, Accuracy: 0.5268227622999407\n",
      "Epoch: 79, Loss_sp: 0.10199185460805893, Loss_mu: 0.1468074768781662, Loss_smr: 0.23575550317764282, Accuracy: 0.5367516301126259\n",
      "Epoch: 80, Loss_sp: 0.03766275942325592, Loss_mu: 0.4109733998775482, Loss_smr: 0.19370540976524353, Accuracy: 0.5265263781861292\n",
      "Epoch: 81, Loss_sp: 0.05374683439731598, Loss_mu: 0.1002098098397255, Loss_smr: 0.23791912198066711, Accuracy: 0.5312685240071132\n",
      "Epoch: 82, Loss_sp: 0.20935550332069397, Loss_mu: 0.1794988065958023, Loss_smr: 0.15211117267608643, Accuracy: 0.5315649081209247\n",
      "Epoch: 83, Loss_sp: 0.004941090010106564, Loss_mu: 0.4604533314704895, Loss_smr: 0.1959909349679947, Accuracy: 0.533787788974511\n",
      "Epoch: 84, Loss_sp: 0.09931455552577972, Loss_mu: 0.29642435908317566, Loss_smr: 0.2365696132183075, Accuracy: 0.525489033787789\n",
      "Epoch: 85, Loss_sp: 0.10597621649503708, Loss_mu: 0.3471388816833496, Loss_smr: 0.1948537528514862, Accuracy: 0.5354179016004742\n",
      "Epoch: 86, Loss_sp: 0.0018213210860267282, Loss_mu: 0.5845110416412354, Loss_smr: 0.1555405706167221, Accuracy: 0.5299347954949615\n",
      "Epoch: 87, Loss_sp: 1.2867610454559326, Loss_mu: 4.384986877441406, Loss_smr: 0.10557664185762405, Accuracy: 0.5363070539419087\n",
      "Epoch: 88, Loss_sp: 0.026725202798843384, Loss_mu: 0.24620279669761658, Loss_smr: 0.15220080316066742, Accuracy: 0.5380853586247777\n",
      "Epoch: 89, Loss_sp: 0.5156785845756531, Loss_mu: 0.3610740303993225, Loss_smr: 0.237204447388649, Accuracy: 0.5342323651452282\n",
      "Epoch: 90, Loss_sp: 0.055538687855005264, Loss_mu: 0.2691245675086975, Loss_smr: 0.19500266015529633, Accuracy: 0.527267338470658\n",
      "Epoch: 91, Loss_sp: 0.06990907341241837, Loss_mu: 0.5301470756530762, Loss_smr: 0.14756828546524048, Accuracy: 0.5389745109662122\n",
      "Epoch: 92, Loss_sp: 0.6897364854812622, Loss_mu: 0.14115798473358154, Loss_smr: 0.15061543881893158, Accuracy: 0.534380557202134\n",
      "Epoch: 93, Loss_sp: 0.0928473100066185, Loss_mu: 0.08818255364894867, Loss_smr: 0.23512157797813416, Accuracy: 0.5336395969176052\n",
      "Epoch: 94, Loss_sp: 0.05749302729964256, Loss_mu: 0.5303348898887634, Loss_smr: 0.1553577035665512, Accuracy: 0.528452874925904\n",
      "Epoch: 95, Loss_sp: 0.3350624144077301, Loss_mu: 0.14217041432857513, Loss_smr: 0.10553223639726639, Accuracy: 0.5277119146413752\n",
      "Epoch: 96, Loss_sp: 0.04298701882362366, Loss_mu: 0.5321062207221985, Loss_smr: 0.2783926725387573, Accuracy: 0.5367516301126259\n",
      "Epoch: 97, Loss_sp: 0.07485216110944748, Loss_mu: 0.64903324842453, Loss_smr: 0.3297373056411743, Accuracy: 0.5321576763485477\n",
      "Epoch: 98, Loss_sp: 0.030167443677783012, Loss_mu: 0.16145367920398712, Loss_smr: 0.1939563751220703, Accuracy: 0.5380853586247777\n",
      "Epoch: 99, Loss_sp: 1.543431282043457, Loss_mu: 0.8561995029449463, Loss_smr: 0.2362738698720932, Accuracy: 0.536158861885003\n",
      "Epoch: 100, Loss_sp: 0.04680952429771423, Loss_mu: 0.17529796063899994, Loss_smr: 0.19629037380218506, Accuracy: 0.534973325429757\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "print(\"model_init\")\n",
    "model = MtlCascadeModel(hp)\n",
    "# print(model)\n",
    "loss_sp = nn.BCEWithLogitsLoss()\n",
    "loss_mu = nn.BCEWithLogitsLoss()\n",
    "loss_smr = nn.MSELoss()\n",
    "\n",
    "out_dict = {\"speech\": [1, 0, 0, 0], \"music\": [0, 1, 0, 0], \"mixture\": [0, 0, 1, 1]}\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = Adam(model.parameters(), lr=0.002)\n",
    "# optimizer = SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.1)\n",
    "\n",
    "print(\"start_training\")\n",
    "for epoch in range(1,hp[\"n_epochs\"]+1):\n",
    "    train(\n",
    "        train_loader, model, epoch, out_dict, loss_sp, loss_mu, loss_smr, optimizer\n",
    "    )\n",
    "# train(\n",
    "#     train_loader, model, hp[\"n_epochs\"], out_dict, loss_sp, loss_mu, loss_smr, optimizer\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
